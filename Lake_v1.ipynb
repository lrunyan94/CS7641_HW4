{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d20cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiive.mdptoolbox as mdptoolbox\n",
    "import hiive.mdptoolbox.mdp as mdp\n",
    "import hiive.mdptoolbox.example as example\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06870b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Code adapted from: https://github.com/ryanym/cs7641/blob/master/assignment4/experiments.py\n",
    "def build_matrix(environment, n_states, n_actions):\n",
    "    \"\"\"\n",
    "    Convert openai discrete environment to Probability matrix and Reward matrix\n",
    "    :param environment:\n",
    "    :param n_states:\n",
    "    :param n_actions:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    reward_matrix = np.zeros((states, actions))\n",
    "    probability_matrix = np.zeros((actions, states, states))\n",
    "\n",
    "\n",
    "    for state in range(n_states):\n",
    "        for action in range(n_actions):\n",
    "            for data_list in environment.env.P[state][action]:\n",
    "                prob, next_state, reward, done = data_list\n",
    "                reward_matrix[state, action] += reward\n",
    "                probability_matrix[action, state, next_state] = prob\n",
    "                probability_matrix[action, state, :] = probability_matrix[action, state, :] / \\\n",
    "                                                       np.sum(probability_matrix[action, state, :])\n",
    "\n",
    "    return probability_matrix, reward_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6351c833",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (Temp/ipykernel_29124/825345886.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\luker\\AppData\\Local\\Temp/ipykernel_29124/825345886.py\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "def vi_experiment(P,R):\n",
    "    vi = mpd.ValueIteration(\n",
    "                            transitions = P,\n",
    "                            reward = R, \n",
    "                            discount = 0.65, \n",
    "                            epsilon = .01,\n",
    "                            max_iter = 1000,\n",
    "                            initial_value=0,\n",
    "                            skip_check+False\n",
    "                            )\n",
    "    vi.setVerbose(True)\n",
    "    vi.run()\n",
    "    expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a915b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', desc=None,map_name=\"4x4\", is_slippery=True)\n",
    "states = env.observation_space.n\n",
    "actions = env.action_space.n\n",
    "P2, R2 = build_matrix(env, states, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f843f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8424c064",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration   Variation\n",
      "         1    1.000000\n",
      "         2    0.365625\n",
      "         3    0.193096\n",
      "         4    0.092324\n",
      "         5    0.048759\n",
      "         6    0.024953\n",
      "         7    0.013021\n",
      "         8    0.007752\n",
      "         9    0.004766\n",
      "Iterating stopped, epsilon-optimal policy found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.0,\n",
       "  'Error': 1.0,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.0,\n",
       "  'Mean V': 0.0625,\n",
       "  'Iteration': 1},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.365625,\n",
       "  'Error': 0.3656250000000001,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.365625,\n",
       "  'Mean V': 0.13105468750000002,\n",
       "  'Iteration': 2},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.558720703125,\n",
       "  'Error': 0.19309570312500002,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.558720703125,\n",
       "  'Mean V': 0.17932861328125002,\n",
       "  'Iteration': 3},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.6510445861816407,\n",
       "  'Error': 0.09232388305664069,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.6510445861816407,\n",
       "  'Mean V': 0.21089523506164554,\n",
       "  'Iteration': 4},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.699803136920929,\n",
       "  'Error': 0.04875855073928825,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.699803136920929,\n",
       "  'Mean V': 0.2320616308152676,\n",
       "  'Iteration': 5},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.7244064865127204,\n",
       "  'Error': 0.02495290537834169,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.7244064865127204,\n",
       "  'Mean V': 0.24495486155763269,\n",
       "  'Iteration': 6},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.7374001305158855,\n",
       "  'Error': 0.013020953048989176,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.7374001305158855,\n",
       "  'Mean V': 0.2527972002469746,\n",
       "  'Iteration': 7},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.7441260719983025,\n",
       "  'Error': 0.007751587316437283,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.7441260719983025,\n",
       "  'Mean V': 0.25735235058391837,\n",
       "  'Iteration': 8},\n",
       " {'State': None,\n",
       "  'Action': None,\n",
       "  'Reward': 1.7476875556819111,\n",
       "  'Error': 0.004765842047021893,\n",
       "  'Time': 0.0,\n",
       "  'Max V': 1.7476875556819111,\n",
       "  'Mean V': 0.2599783013727911,\n",
       "  'Iteration': 9}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi = mdp.ValueIteration(P2,R2,0.65)\n",
    "vi.setVerbose()\n",
    "vi_stat = vi.run()\n",
    "vi_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.policy\n",
    "policy = np.reshape(vi.policy,(4,4))\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592eaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3dc0aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'S', b'F', b'F', b'F', b'F', b'H', b'F', b'H', b'F', b'F', b'F',\n",
       "       b'H', b'H', b'F', b'F', b'G'], dtype='|S1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.desc\n",
    "desc = np.reshape(env.desc,16)\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accee463",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_test = []\n",
    "s_reward = 0\n",
    "f_reward = 0\n",
    "h_reward = 0\n",
    "g_reward = 1\n",
    "\n",
    "for row in range(env.nrow):\n",
    "    for col in range(env.ncol):\n",
    "        square = env.desc[row][col]\n",
    "        if square == b'S':\n",
    "            reward_test.append(s_reward)\n",
    "        if square == b'F':\n",
    "            reward_test.append(f_reward)\n",
    "        if square == b'H':\n",
    "            reward_test.append(h_reward)\n",
    "        if square == b'G':\n",
    "            reward_test.append(g_reward)\n",
    "print(reward_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi1 = mdp.ValueIteration(P2,R2,0.65)\n",
    "vi1.setVerbose()\n",
    "vi1_stat = vi1.run()\n",
    "#vi1_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi2 = mdp.ValueIteration(P2,reward_test,0.65)\n",
    "vi2.setVerbose()\n",
    "vi2_stat = vi2.run()\n",
    "#vi2_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53392e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi1.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec27ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi2.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ba763",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi1.policy\n",
    "policy1 = np.reshape(vi1.policy,(4,4))\n",
    "policy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd5920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vi2.policy\n",
    "policy2 = np.reshape(vi2.policy,(4,4))\n",
    "policy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi1.V\n",
    "values1 = np.reshape(vi1.V,(4,4))\n",
    "values1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578591cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi2.V\n",
    "values2 = np.reshape(vi2.V,(4,4))\n",
    "values2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21400116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox, mdptoolbox.example\n",
    "P, R = mdptoolbox.example.forest()\n",
    "vi = mdptoolbox.mdp.ValueIteration(P, R, 0.96)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24dbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
